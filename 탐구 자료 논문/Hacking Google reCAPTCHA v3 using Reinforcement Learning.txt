이 연구는 강화학습(Reinforcement Learning, RL) 방법론을 사용하여 Google의 reCAPTCHA v3를 우회하는 방법을 제시한다. 문제를 그리드 월드로 형식화하여 에이전트가 마우스를 움직이고 reCAPTCHA 버튼을 클릭하여 높은 점수를 받는 방법을 학습한다. 

강화학습에서 '그리드 월드'는 일반적으로 에이전트가 배울 수 있는 환경을 단순화하여 표현한 모델이다. 이 환경은 격자(그리드)로 나누어져 있으며, 각 격자 셀은 에이전트가 위치할 수 있는 공간을 나타낸다. 에이전트는 보상을 최대화하기 위해 격자 내에서 움직이며, 특정 목표(이 경우 reCAPTCHA 버튼)를 찾아 클릭해야 합니다.
즉, '그리드 월드의 셀 크기를 변화시켜 에이전트의 성능을 연구했다'는 말은, 연구자들이 환경을 구성하는 각 셀의 크기를 변경하면서 에이전트가 얼마나 잘 학습하고 목표를 달성하는지를 관찰했다는 의미이다. 셀 크기는 에이전트가 한 번에 이동할 수 있는 거리와 관련이 있으며, 셀이 크면 에이전트는 더 큰 단계로 이동할 수 있지만, 그것은 에이전트가 더 적은 수의 결정을 내려야 함을 의미한다.
또한 '에이전트가 목표에 큰 걸음을 내딛을 때 성능이 떨어지는 것을 발견했습니다'는 에이전트가 한 번에 큰 이동을 할 때(즉, 큰 셀 크기로 설정할 때), 그것이 오히려 목표 달성에 비효율적일 수 있음을 의미한다. 큰 이동은 에이전트가 필요한 미세 조정을 수행할 수 있는 능력을 제한할 수 있으며, 이는 특히 정밀한 작업이 필요한 작업에서 문제가 될 수 있다. 예를 들어, 에이전트가 reCAPTCHA 버튼 정확히 클릭해야 할 경우, 너무 큰 단계로 이동하면 버튼을 놓칠 수 있다.

마지막으로, 어떤 그리드 해상도에서든 reCAPTCHA 시스템을 물리치기 위해 분할 정복 전략을 사용한다. 제안된 방법은 100×100 그리드에서 97.4%의 성공률을, 1000×1000 화면 해상도에서 96.7%의 성공률을 달성했다.

이 연구는 인공지능(AI)이 최근 몇 년간 기계학습(ML), 특히 딥러닝(DL)에서 이루어진 진전 덕분에 전례 없는 성공을 거두고 있지만, ML 알고리즘을 기반으로 하는 AI 시스템, 예를 들어 reCAPTCHA v3가 여전히 자동화된 공격에 취약하다는 것을 보여준다. 

reCAPTCHA v1은 사용자가 테스트를 통과하기 위해 정확히 입력해야 하는 왜곡된 텍스트를 제시했다. 이 버전은 ML 기반 시스템을 사용하여 텍스트를 분할하고 인식하여 98%의 정확도로 패배했다. 그 결과, 이미지 기반 및 오디오 기반의 reCAPTCHA가 두 번째 버전으로 도입되었다. 연구자들은 또한 ML, 특히 DL을 사용하여 이러한 버전을 해킹하는 데 성공했다. 
2018년 10월 29일에 발표된 공식 세 번째 버전은 모든 사용자 인터페이스를 제거했다. Google의 reCAPTCHA v3는 ML을 사용하여 0.0부터 1.0 사이의 위험 평가 점수를 반환한다. 1.0에 가까운 점수는 사용자가 인간임을 의미한다.

연구자들은 이 reCAPTCHA 버전을 해결하기 위해 RL 형식화를 도입했다. 이 접근법은 프로그램적이다. 먼저, 최신 RL 알고리즘으로 해결할 수 있는 마르코프 결정 프로세스(Markov Decision Process, MDP)로 문제의 타당한 형식화를 제안하고, 그 다음 새로운 환경을 도입한다.

이 연구는 강화학습을 사용하여 reCAPTCHA v3의 보안을 뚫을 수 있음을 보여주며, 이러한 방법이 실제로 높은 성공률로 구현될 수 있음을 시사한다.​​





